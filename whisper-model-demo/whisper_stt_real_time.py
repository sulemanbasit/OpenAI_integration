import whisper
import pyaudio
import numpy as np
import torch
import time

# Load Whisper model (medium is a good balance of speed and accuracy)
model = whisper.load_model("small")

# Audio Recording Parameters
FORMAT = pyaudio.paInt16  # 16-bit audio
CHANNELS = 1              # Mono audio
RATE = 16000              # Whisper expects 16kHz
CHUNK = 1024              # Reduce buffer size to prevent overflow

# Initialize PyAudio
audio = pyaudio.PyAudio()

# Start Recording from Microphone
stream = audio.open(format=FORMAT, channels=CHANNELS,
                    rate=RATE, input=True,
                    frames_per_buffer=CHUNK)

print("üéôÔ∏è Speak now... Press Ctrl+C to stop.")

def record_audio():
    """ Capture audio from the microphone and return as a numpy array. """
    frames = []
    record_start_time = time.time()
    
    while time.time() - record_start_time < 10:
        try:
            data = stream.read(CHUNK, exception_on_overflow=False)  # ‚úÖ Fix buffer overflow
            frames.append(np.frombuffer(data, dtype=np.int16))
        except OSError as e:
            print(f"‚ö†Ô∏è Warning: Audio buffer overflow - {e}")
            break  # Prevent loop freezing

    record_end_time = time.time()
    record_duration = record_end_time - record_start_time  # ‚è±Ô∏è Time recording

    # Convert to numpy array
    audio_data = np.concatenate(frames, axis=0).astype(np.float32)
    audio_data /= np.max(np.abs(audio_data))  # Normalize audio
    return audio_data, record_duration

try:
    while True:
        # Step 1Ô∏è‚É£: Capture Audio üéôÔ∏è
        print("recording audio")
        audio_input, record_time = record_audio()
        print("audio recorded\n")

        if len(audio_input) == 0:
            print("‚ö†Ô∏è No valid audio recorded, skipping transcription.")
            continue

        # Step 2Ô∏è‚É£: Transcription & Language Detection üìù
        transcribe_start_time = time.time()  # Start timer for transcription
        print("transcribing started")

        result = model.transcribe(audio_input, fp16=False)  # ‚úÖ No more warnings
        
        transcribe_end_time = time.time()
        transcribe_time = transcribe_end_time - transcribe_start_time  # ‚è±Ô∏è Time for transcription
        
        detected_language = result['language']
        transcribed_text = result['text']
        print("transcribing finished\n")

        print(f"üó£Ô∏è Detected Language: {detected_language.upper()} (‚è±Ô∏è {transcribe_time:.2f} sec)")
        print(f"üìù Transcription: {transcribed_text}")

        # Step 3Ô∏è‚É£: Translation (If Needed) üåç
        translate_time = 0  # Default if no translation occurs
        if detected_language != "en":
            translate_start_time = time.time()
            translated_text = model.transcribe(audio_input, task="translate")["text"]
            translate_end_time = time.time()
            translate_time = translate_end_time - translate_start_time  # ‚è±Ô∏è Time for translation
            
            print(f"üåç Translated to English: {translated_text} (‚è±Ô∏è {translate_time:.2f} sec)")

        print("-" * 50)

        # üöÄ Total Execution Time
        total_time = record_time + transcribe_time + translate_time
        print("\nüîπ **Performance Summary** üîπ")
        print(f"üéôÔ∏è Recording Time: {record_time:.2f} sec")
        print(f"üìù Transcription Time: {transcribe_time:.2f} sec")
        if detected_language != "en":
            print(f"üåç Translation Time: {translate_time:.2f} sec")
        print(f"üöÄ Total Execution Time: {total_time:.2f} sec")
        print("-" * 50)

except KeyboardInterrupt:
    print("\nüõë Stopping...")
    stream.stop_stream()
    stream.close()
    audio.terminate()


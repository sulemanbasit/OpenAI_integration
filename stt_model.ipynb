{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vosk in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.3.44)\n",
      "Requirement already satisfied: cffi>=1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from vosk) (1.17.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from vosk) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from vosk) (4.67.1)\n",
      "Requirement already satisfied: srt in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from vosk) (3.5.3)\n",
      "Requirement already satisfied: websockets in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from vosk) (15.0)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from cffi>=1.0->vosk) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->vosk) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->vosk) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->vosk) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->vosk) (2024.12.14)\n",
      "Requirement already satisfied: pydub in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.25.1)\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://formulae.brew.sh/api/formula.jws.json\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://formulae.brew.sh/api/cask.jws.json\u001b[0m\n",
      "\u001b[33mWarning:\u001b[0m ffmpeg 7.1_4 is already installed and up-to-date.\n",
      "To reinstall 7.1_4, run:\n",
      "  brew reinstall ffmpeg\n"
     ]
    }
   ],
   "source": [
    "!pip3 install vosk\n",
    "!pip3 install pydub\n",
    "!brew install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import json\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_wav_file(file_path):\n",
    "    \"\"\"\n",
    "    Check if the file is in WAV format\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with wave.open(file_path, 'rb') as wav_file:\n",
    "            return True\n",
    "    except wave.Error:\n",
    "        return False\n",
    "\n",
    "def convert_to_wav_ffmpeg(input_file, output_file=None):\n",
    "    \"\"\"\n",
    "    Convert audio file to WAV format using FFmpeg\n",
    "    Returns the path to the converted file\n",
    "    \"\"\"\n",
    "    if output_file is None:\n",
    "        # Create output filename in the same directory as input file\n",
    "        output_file = str(Path(input_file).with_suffix('.wav'))\n",
    "    \n",
    "    try:\n",
    "        command = [\n",
    "            'ffmpeg',\n",
    "            '-i', input_file,\n",
    "            '-acodec', 'pcm_s16le',\n",
    "            '-ac', '1',\n",
    "            '-ar', '16000',\n",
    "            output_file,\n",
    "            '-y'  # Overwrite output file if it exists\n",
    "        ]\n",
    "        # Using capture_output=True to capture both stdout and stderr\n",
    "        subprocess.run(command, check=True, capture_output=True)\n",
    "        return output_file\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error converting file: {e.stderr.decode()}\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(\"FFmpeg not found. Please install FFmpeg on your system.\")\n",
    "        return None\n",
    "\n",
    "def transcribe_audio(audio_file_path, model_path=\"vosk-model-small-en-us-0.15\"):\n",
    "    \"\"\"\n",
    "    Main function to handle audio transcription\n",
    "    Checks format, converts if necessary, and performs transcription\n",
    "    \"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Please download the model from https://alphacephei.com/vosk/models and unpack as {model_path}\")\n",
    "        return None\n",
    "\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(audio_file_path):\n",
    "        print(f\"Audio file not found: {audio_file_path}\")\n",
    "        return None\n",
    "\n",
    "    wav_file_path = audio_file_path\n",
    "    converted = False\n",
    "\n",
    "    # Check if the file is WAV format, if not convert it\n",
    "    if not is_wav_file(audio_file_path):\n",
    "        print(f\"Converting {audio_file_path} to WAV format...\")\n",
    "        wav_file_path = convert_to_wav_ffmpeg(audio_file_path)\n",
    "        if wav_file_path is None:\n",
    "            print(\"Conversion failed.\")\n",
    "            return None\n",
    "        converted = True\n",
    "\n",
    "    try:\n",
    "        # Load the model\n",
    "        model = Model(model_path)\n",
    "        \n",
    "        # Open the audio file\n",
    "        wf = wave.open(wav_file_path, \"rb\")\n",
    "        \n",
    "        # Check if the audio file has the right format\n",
    "        if wf.getnchannels() != 1:\n",
    "            print(\"Converting to mono channel...\")\n",
    "            temp_path = str(Path(wav_file_path).with_name('temp_mono.wav'))\n",
    "            convert_to_wav_ffmpeg(wav_file_path, temp_path)\n",
    "            wf.close()\n",
    "            wf = wave.open(temp_path, \"rb\")\n",
    "        \n",
    "        # Create recognizer\n",
    "        recognizer = KaldiRecognizer(model, wf.getframerate())\n",
    "        recognizer.SetWords(True)\n",
    "        \n",
    "        # Process audio file\n",
    "        results = []\n",
    "        while True:\n",
    "            data = wf.readframes(4000)\n",
    "            if len(data) == 0:\n",
    "                break\n",
    "            if recognizer.AcceptWaveform(data):\n",
    "                part_result = json.loads(recognizer.Result())\n",
    "                results.append(part_result.get(\"text\", \"\"))\n",
    "        \n",
    "        # Get final bits of audio and flush the pipeline\n",
    "        part_result = json.loads(recognizer.FinalResult())\n",
    "        results.append(part_result.get(\"text\", \"\"))\n",
    "        \n",
    "        # Clean up\n",
    "        wf.close()\n",
    "        \n",
    "        # Remove temporary files if created\n",
    "        if converted:\n",
    "            try:\n",
    "                if os.path.exists('temp_mono.wav'):\n",
    "                    os.remove('temp_mono.wav')\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not remove temporary file: {e}\")\n",
    "        \n",
    "        # Combine results\n",
    "        transcript = \" \".join(results)\n",
    "        return transcript.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during transcription: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting transcription...\n",
      "Converting Test2.m4a to WAV format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=10 max-active=3000 lattice-beam=2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from vosk-model-small-en-us-0.15/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from vosk-model-small-en-us-0.15/graph/HCLr.fst vosk-model-small-en-us-0.15/graph/Gr.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:303) Loading winfo vosk-model-small-en-us-0.15/graph/phones/word_boundary.int\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription completed:\n",
      "i'd like help assessing the effectiveness and security of our current digital dunes right now we're using microsoft systems for our online server share point and using google tools for communication email chad etc we're still using more basic systems like excel for time dragging which you would like to graduate from and perhaps most importantly i'd like some help with how to make sure our system does secure and digitally slit safe i being best practices to help us ensure security\n"
     ]
    }
   ],
   "source": [
    " # Example usage\n",
    "audio_file = \"Test2.m4a\"  # Replace with your audio file path\n",
    "\n",
    "# Make sure you have downloaded the Vosk model and specified the correct path\n",
    "model_path = \"vosk-model-small-en-us-0.15\"  # Replace with your model path\n",
    "\n",
    "print(\"Starting transcription...\")\n",
    "transcript = transcribe_audio(audio_file, model_path)\n",
    "\n",
    "if transcript:\n",
    "    print(\"Transcription completed:\")\n",
    "    print(transcript)\n",
    "else:\n",
    "    print(\"Transcription failed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
